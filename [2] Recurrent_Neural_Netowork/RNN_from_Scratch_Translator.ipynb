{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN ENCODER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyEncoder(nn.Module):\n",
    "    def __init__(self,input_vocab_size,embed_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_vocab_size,embed_size)\n",
    "\n",
    "        # RNN parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_h= nn.Parameter(torch.randn(hidden_size,hidden_size))\n",
    "        self.W_x = nn.Parameter(torch.randn(hidden_size,embed_size))\n",
    "        self.b = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "\n",
    "    def forward(self,src_tokens):\n",
    "        \"\"\"\n",
    "        src_tokens: shape (src_len,)\n",
    "        Returns final hidden state (hidden_size,)\n",
    "        \"\"\"\n",
    "\n",
    "        h = torch.zeros(self.hidden_size)\n",
    "\n",
    "        for t in range(src_tokens.shape[0]):\n",
    "            token_id = src_tokens[t]\n",
    "            x_t = self.embedding(token_id)\n",
    "\n",
    "            h = torch.tanh(\n",
    "                torch.mv(self.W_h,h) +\n",
    "                torch.mv(self.W_x,x_t) +\n",
    "                self.b\n",
    "            )\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyDecoder(nn.Module):\n",
    "    def __init__(self,output_vocab_size,embed_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_vocab_size,embed_size)\n",
    "\n",
    "        self.hidden_size= hidden_size\n",
    "        self.W_h = nn.Parameter(torch.randn(hidden_size,hidden_size))\n",
    "        self.W_x = nn.Parameter(torch.randn(hidden_size,embed_size))\n",
    "        self.b = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Output Projection\n",
    "\n",
    "        self.W_out = nn.Parameter(torch.randn(output_vocab_size,))\n",
    "        self.b_out = nn.Parameter(torch.zeros(output_vocab_size))\n",
    "\n",
    "\n",
    "    def forward(self,dec_tokens,init_hidden):\n",
    "        h = init_hidden\n",
    "        logits_list = []\n",
    "\n",
    "        for t in range(dec_tokens.shape[0]):\n",
    "            token_id = dec_tokens[t]\n",
    "            x_t = self.embedding(token_id)\n",
    "\n",
    "\n",
    "            h = torch.tanh(\n",
    "                torch.mv(self.W_h,h)+\n",
    "                torch.mv(self.W_x,x_t)+\n",
    "                self.b\n",
    "            )\n",
    "            logits_t = torch.mv(self.W_out,h) + self.b_out \n",
    "            logits_list.append(logits_t.unsqueeze(0))\n",
    "\n",
    "        return torch.cat(logits_list,dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE DATA\n",
    "\n",
    "\"I go <EOS>\" --> \"मैं जाता हूँ <EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG_VOCAB_SIZE = 3  # I=0, go=1, <EOS>=2\n",
    "HIN_VOCAB_SIZE = 4  # मैं=1, जाता=2, हूँ=3, <EOS>=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map IDs to words for printing \n",
    "\n",
    "HIN_ID2WORD = {\n",
    "    0:\"<GO>\",\n",
    "    1:\"मैं\",\n",
    "    2:\"जाता\",\n",
    "    3:\"हूँ\",\n",
    "    4:\"<EOS>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 1\n",
    "HIDDEN_SIZE = 2\n",
    "\n",
    "encoder = TinyEncoder(ENG_VOCAB_SIZE,EMBED_SIZE,HIDDEN_SIZE)\n",
    "decoder = TinyDecoder(HIN_VOCAB_SIZE,EMBED_SIZE,HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder target: \"मैं जाता हूँ <EOS>\" => [1,2,3,4]\"\n",
    "# We'll do teacher forcing in training:\n",
    "\n",
    "decoder_input = torch.tensor([0,1,2,3]) # \"मैं जाता हूँ <EOS>\" => [1,2,3,4]\n",
    "decoder_target = torch.tensor([1,2,3,4]) # \"मैं जाता हूँ <EOS>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
